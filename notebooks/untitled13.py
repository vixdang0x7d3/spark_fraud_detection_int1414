# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19OgFvV_syA8Zw_EhWGbnjw0GydMKclwy
"""

from google.colab import files
files.upload()

!pip install kaggle
!mkdir ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d kartik2112/fraud-detection

!unzip creditcardfraud.zip

import pandas as pd
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.ensemble import RandomForestClassifier
import datetime as dt

df=pd.read_csv('/content/fraudTrain.csv')

df.drop_duplicates(inplace=True)

# Feature engineering
df['age'] = dt.date.today().year - pd.to_datetime(df['dob']).dt.year
df['hour'] = pd.to_datetime(df['trans_date_trans_time']).dt.hour
df['day'] = pd.to_datetime(df['trans_date_trans_time']).dt.dayofweek
df['month'] = pd.to_datetime(df['trans_date_trans_time']).dt.month

# Subset the training data
train = df[['category','amt','zip','lat','long','city_pop','merch_lat','merch_long','age','hour','day','month','is_fraud']]

# Load and preprocess test data
test = pd.read_csv('/content/fraudTest.csv')
test['age'] = dt.date.today().year - pd.to_datetime(test['dob']).dt.year
test['hour'] = pd.to_datetime(test['trans_date_trans_time']).dt.hour
test['day'] = pd.to_datetime(test['trans_date_trans_time']).dt.dayofweek
test['month'] = pd.to_datetime(test['trans_date_trans_time']).dt.month

test = test[['category','amt','zip','lat','long','city_pop','merch_lat','merch_long','age','hour','day','month','is_fraud']]

# Create consistent dummy variables
train_dummies = pd.get_dummies(train['category'], prefix='category', drop_first=True)
test_dummies = pd.get_dummies(test['category'], prefix='category', drop_first=True)

# Ensure both have the same columns
all_dummy_cols = list(set(train_dummies.columns) | set(test_dummies.columns))
for col in all_dummy_cols:
    if col not in train_dummies.columns:
        train_dummies[col] = 0
    if col not in test_dummies.columns:
        test_dummies[col] = 0

# Sort columns to ensure same order
train_dummies = train_dummies[sorted(all_dummy_cols)]
test_dummies = test_dummies[sorted(all_dummy_cols)]

# Rebuild datasets with consistent dummy variables
train_final = pd.concat([
    train.drop('category', axis=1),
    train_dummies
], axis=1)

test_final = pd.concat([
    test.drop('category', axis=1),
    test_dummies
], axis=1)

y_train = train_final['is_fraud'].values
X_train_final = train_final.drop("is_fraud", axis=1).values
y_test = test_final['is_fraud'].values
X_test_final = test_final.drop("is_fraud", axis=1).values


print(f"Training features shape: {X_train_final.shape}")
print(f"Test features shape: {X_test_final.shape}")

import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import numpy as np
# scaler = StandardScaler()
# X_scaled = scaler.fit_transform(X_train)
# pca_full = PCA()
# pca_full.fit(X_scaled)

# plt.plot(np.cumsum(pca_full.explained_variance_ratio_))
# plt.xlabel('Số thành phần')
# plt.ylabel('Tỷ lệ phương sai tích lũy')
# plt.grid(True)
# plt.show()

# Standardization (fit on training data only)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_final)
X_test_scaled = scaler.transform(X_test_final)  # Use same scaler
# PCA Analysis
pca_full = PCA()
pca_full.fit(X_train_scaled)

plt.figure(figsize=(10, 6))
plt.plot(np.cumsum(pca_full.explained_variance_ratio_))
plt.xlabel('Number of Components')
plt.ylabel('Cumulative Explained Variance')
plt.title('PCA Explained Variance')
plt.grid(True)
plt.show()

# Find optimal number of components for 95% variance
n_components_95 = np.argmax(np.cumsum(pca_full.explained_variance_ratio_) >= 0.95) + 1
print(f"Components needed for 95% variance: {n_components_95}")

# # 2. Khởi tạo PCA với 18 thành phần
# pca = PCA(n_components=18)

# # 3. Fit và transform
# X_pca = pca.fit_transform(X_scaled)

# # 4. Xem kết quả
# print("Shape ban đầu:", X_train.shape)
# print("Shape sau PCA:", X_pca.shape)

# # 5. Xem tỷ lệ phương sai
# explained_variance = pca.explained_variance_ratio_
# print("Phần trăm phương sai của từng thành phần:", explained_variance)
# print("Tổng phương sai giải thích:", np.sum(explained_variance))


# Apply PCA with optimal components
pca = PCA(n_components=min(18, n_components_95))  # Use 18 or optimal, whichever is smaller
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)  # Use same PCA transformation

print(f"Original shape: {X_train_final.shape}")
print(f"Shape after PCA: {X_train_pca.shape}")
print(f"Explained variance ratio: {pca.explained_variance_ratio_}")
print(f"Total explained variance: {np.sum(pca.explained_variance_ratio_):.4f}")

# Apply SMOTE for class balance
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train_pca, y_train)

print(f"Original class distribution: {np.bincount(y_train)}")
print(f"After SMOTE class distribution: {np.bincount(y_resampled)}")

# method= SMOTE()
# X_resampled, y_resampled = method.fit_resample(X_pca, y_train)
# model2 = RandomForestClassifier(random_state=5)
# model2.fit(X_resampled,y_resampled)
# predicted=model2.predict(X_test)
# print('Classification report:\n', classification_report(y_test, predicted))
# conf_mat = confusion_matrix(y_true=y_test, y_pred=predicted)
# print('Confusion matrix:\n', conf_mat)
# print('Share of Non-Fraud in Test Data:', 1-round(y_test.sum()/len(y_test),4))

# Train Random Forest model
model = RandomForestClassifier(
    n_estimators=50,
    random_state=42,
    class_weight='balanced',  # Additional protection against class imbalance,
    n_jobs=-1
)
model.fit(X_resampled, y_resampled)

# Make predictions
y_pred = model.predict(X_test_pca)

# Evaluate model
print('\n=== MODEL EVALUATION ===')
print('Classification Report:')
print(classification_report(y_test, y_pred))

print('\nConfusion Matrix:')
conf_mat = confusion_matrix(y_test, y_pred)
print(conf_mat)

# Additional metrics
tn, fp, fn, tp = conf_mat.ravel()
precision = tp / (tp + fp) if (tp + fp) > 0 else 0
recall = tp / (tp + fn) if (tp + fn) > 0 else 0
f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

print(f'\nDetailed Metrics:')
print(f'True Negatives: {tn}')
print(f'False Positives: {fp}')
print(f'False Negatives: {fn}')
print(f'True Positives: {tp}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1-Score: {f1:.4f}')

print(f'\nShare of Non-Fraud in Test Data: {1-round(y_test.sum()/len(y_test),4):.4f}')
print(f'Share of Fraud in Test Data: {round(y_test.sum()/len(y_test),4):.4f}')